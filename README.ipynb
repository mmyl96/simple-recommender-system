{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font size=7>CF Recommender System</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>Two major kinds of recommender systems:\n",
    "- **Content-Based**: items are recommended by their intrinsic similarity (clustering).\n",
    "- **Collaborative Filtering**: items are recommended based on the ratings of users.\n",
    "\n",
    "The main benefit of CF recommender system is it only need the ratings from users. We do not need to add many tags to every item. It vastly save human labors and time.\n",
    "Two main CF methods:\n",
    "- **Neighborhood Method**\n",
    "- **Latent Factor Method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>There is no absolute rank between two methods. In this movie recommender system project, I **only use Neighborhood Method**.\n",
    "<br\\>\n",
    "    <br\\>\n",
    "The core idea of Neighborhood Method is to remove users’ bias and movies’ popularity. It is well acknowledged that some users are more generous than others and always give ratings higher than average rating while some may always give lower ratings since they are more critical. For the same reason, a movie may have higher or lower rating due to its release time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font size=5>Algorithm Part</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Data Preprocessing\n",
    "<br\\>\n",
    "<font size=3.5>Initially, suppose we have a big matrix $R$ consisted with existed ratings, which $r(i, j)$ is the rating that user $u_i$ gives movie $m_j$. In order to make rating $r(i, j)$ be more informative, replacing every $r(i, j)$ in $R$ by the values $r^{*}(i, j) = r(i, j) - \\bar{r}$, where $\\bar{r}$ means average rating over all existed ratings.\n",
    "<br\\>\n",
    "    <br\\>\n",
    "Now, the rating is more informative, if rating $r^{*}(i, j) < 0$, it means user  $u_i$ like movie $m_j$ more than average. However, we do not remove personal bias and movie popularity. We need to remove these biases and then we will get a more accurate rating matrix.\n",
    "<br\\>\n",
    "    <br\\>\n",
    "Therefore, we introduce for every user $u_i$ a variable $\\nu_{i}$ standing for personal bias and for every movie $m_j$ a variable $\\mu_{j}$ standing for its popularity. Generally, we got two 1D vectors $\\vec{\\nu} and  \\vec{\\mu}$. Then, in order to get the best vectors, we should minimize <font size=4>$$Loss(\\vec{\\nu}, \\vec{\\mu}) = \\sum_{(i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})^{2}$$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_matrix(df):\n",
    "    nusers = config.nusers\n",
    "    nmovies = config.nmovies\n",
    "    ratings = np.zeros(shape=(nusers,nmovies))\n",
    "    true_value = np.zeros(shape=(nusers,nmovies))\n",
    "    avg = df[\"rating\"].mean()\n",
    "    for i in range(len(df)):\n",
    "        userID = int(df.loc[i][0]-1)\n",
    "        movieID = int(df.loc[i][1]-1)\n",
    "        rating = float(df.loc[i][2])\n",
    "        ## Get a more informative dataset\n",
    "        ratings[userID, movieID] = rating - avg\n",
    "        true_value[userID, movieID] = 1\n",
    "    return ratings, true_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Learning\n",
    "<br\\>\n",
    "<font size=3.5>This **Least Squares Problem** could be easily solved by **Gradient Descent**: <font size=4>$$\\frac{\\partial Loss(\\vec{\\nu}, \\vec{\\mu})}{\\partial \\mu_{j}} = \\frac{\\partial \\sum_{(i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})^{2}}{\\partial \\mu_{j}} = -2 \\sum_{i : (i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})$$ $$\\frac{\\partial Loss(\\vec{\\nu}, \\vec{\\mu})}{\\partial \\nu_{i}} = \\frac{\\partial \\sum_{(i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})^{2}}{\\partial \\nu_{i}} = -2 \\sum_{j : (i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})$$</font> Typically, in order to avoid overfitting in least squares problem, introduce **L2 Regularization**: <font size=4>$$Loss(\\vec{\\nu}, \\vec{\\mu}) = \\sum_{(i, j) \\in R}( r^{*}(i, j) - \\nu_{i} - \\mu_{j})^{2} + \\lambda (\\sum_{i}\\nu_i^{2} + \\sum_{i}\\mu_j^{2})$$</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def learning(learning_rate, epoch, ratings, true_value):\n",
    "    ## Initialization of user bias vector and movie bias vector\n",
    "    V = np.zeros(ratings.shape[0])\n",
    "    U = np.zeros(ratings.shape[1])\n",
    "    for _ in range(1, epoch+1):\n",
    "        F = np.add.outer(V,U)\n",
    "        ## Solve this problem by Gradient Descent with L2 Regularization\n",
    "        gradient_V = np.sum(ratings-F*true_value, axis = 1) - 2*config.lamda * V\n",
    "        gradient_U = np.sum(ratings-F*true_value, axis = 0) - 2*config.lamda * U\n",
    "        V += 2*learning_rate*gradient_V\n",
    "        U += 2*learning_rate*gradient_U\n",
    "        if _%100 == 0:\n",
    "            print(f\"{_//100}/{epoch//100} has finished\")\n",
    "            print(\"Current Loss is: \", np.sum((ratings-F*true_value)**2, axis = (0,1)))\n",
    "    bias_save(\"userID\", V)\n",
    "    bias_save(\"movieID\", U)\n",
    "    return V, U"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>After get the vectors of $\\vec{\\nu}$ and $\\vec{\\mu}$. We could get $\\tilde{r}(i, j) = r^{*}(i, j) - \\nu_{i} - \\mu_{j}$ and update the matrix from $R^{*}$ to $\\tilde{R}$.\n",
    "<br\\>\n",
    "    <br\\>\n",
    "Now, we are ready to compute the similarity between users or movies. \n",
    "- **Cosine Similarity**: only consider the direction of two vectors.$$cos(\\vec{u_i}, \\vec{u_k}) = \\frac{u_i^\\top u_k}{\\sqrt{(u_i^\\top u_i)}\\sqrt{(u_k^\\top u_k)}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(u_i, u_k):\n",
    "    # Cosine Similarity\n",
    "    return np.dot(u_i, u_k)/(np.sqrt(np.dot(u_i, u_i))*np.sqrt(np.dot(u_k, u_k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3.5>Note that we are not only interested in the most **similar** users but also the most **dissimilar** users. Therefore, we should consider the top-k users with largest similarity $|sim(U_i, U_k)|$. There are many method to get top-k result fast, such as binary heap, deterministic select, quick select, here I use quick select."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Prediction\n",
    "<br\\>\n",
    "<font size=3.5>After we did all of above preprocessing, we could predict a movie for a particular user. The core idea here is to find the movie which most similar users like best or the movie which most dissimilar users dislike. In addition, do not forget to add the personal bias and popularity:$$pred(i, j) = \\nu_{i} + \\mu_{j} + \\frac{\\sum_{k \\in top-k}sim(U_i, U_k)\\tilde{r}(j, k)}{\\sum_{k \\in top-k}|sim(U_i, U_k)|}$$ Definitely, we will recommend the movie with highest prediction score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_rating(userID, movieID):\n",
    "    values = np.zeros(config.nusers)\n",
    "    u_idx = np.nonzero(ratings[:,movieID-1])[0] # Users who saw movie\n",
    "    for u in u_idx:\n",
    "        if u == userID:\n",
    "            continue\n",
    "        values[u] = similarity(ratings[userID-1], ratings[u])\n",
    "    Q = TopK(values, config.MaxUserNumber) # Fast get results and their indices by using quick select\n",
    "    sim, idx = Q.answer()\n",
    "    if sum(abs(sim)) == 0: # Avoid zero division\n",
    "        return 0\n",
    "    ## Note that we do not only consider most similar but also most dissimilar\n",
    "    return V[userID-1] + U[movieID-1] + sum([sim[i]*ratings[idx[i],movieID-1] for i in range(config.MaxUserNumber)])/sum(abs(sim))\n",
    "\n",
    "def prediction(userID):\n",
    "    m_idx = np.where(ratings[userID-1]==0)[0] # Movies which user did not see yet\n",
    "    values = np.zeros(config.nmovies)\n",
    "    for m in m_idx:\n",
    "        values[m] = pred_rating(userID, m+1)\n",
    "    return np.argmax(values)+1 # Return index of movieID with highest score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
